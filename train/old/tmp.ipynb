{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c7743d8a56406bb34ce028d2dbef20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">self adaptive\n",
       "</pre>\n"
      ],
      "text/plain": [
       "self adaptive\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">self adaptive\n",
       "</pre>\n"
      ],
      "text/plain": [
       "self adaptive\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax \n",
    "from optax.contrib import reduce_on_plateau\n",
    "from jax import vmap\n",
    "import jax_dataloader as jdl\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "import jax.experimental.mesh_utils as mesh_utils\n",
    "import jax.sharding as jshard\n",
    "\n",
    "#PATH = \"/cluster/work/eirikaf/\"\n",
    "PATH = r\"C:\\Users\\eirik\\orbax\"\n",
    "#PATH = None\n",
    "\n",
    "# LOAD DATA\n",
    "#data = jnp.load(\"/cluster/home/eirikaf/phlearn-summer24/eirik_prosjektoppgave/data/advection.npz\")\n",
    "data = jnp.load(r\"C:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\data\\advection.npz\")\n",
    "x = jnp.array(data['x'])\n",
    "t = jnp.array(data['t'])\n",
    "a_train = jnp.array(data['a_train'])\n",
    "u_train = jnp.array(data['u_train'])\n",
    "a_val = jnp.array(data['a_val'])\n",
    "u_val = jnp.array(data['u_val'])\n",
    "a_test = jnp.array(data['a_test'])\n",
    "u_test = jnp.array(data['u_test'])\n",
    "\n",
    "# SET PARAMETERS\n",
    "P = x[-1]\n",
    "T = t[-1]\n",
    "M = len(x) - 1\n",
    "N = len(t) - 1\n",
    "NUMBER_OF_SENSORS = M + 1\n",
    "N = len(t)-1\n",
    "NUMBER_OF_SENSORS = M+1\n",
    "\n",
    "# NORMALIZE DATA\n",
    "u_normalizer = UnitGaussianNormalizer(u_train)\n",
    "a_normalizer = UnitGaussianNormalizer(a_train)\n",
    "x_normalizer = UnitGaussianNormalizer(x)\n",
    "t_normalizer = UnitGaussianNormalizer(t)\n",
    "\n",
    "u_train_n = u_normalizer.encode(u_train)\n",
    "a_train_n = a_normalizer.encode(a_train)\n",
    "\n",
    "u_val_n = u_normalizer.encode(u_val)\n",
    "a_val_n = a_normalizer.encode(a_val)\n",
    "\n",
    "x_n = x_normalizer.encode(x)\n",
    "t_n = t_normalizer.encode(t)\n",
    "\n",
    "# Set x and t as class attributes, since they are constant throughout the training\n",
    "Trainer.x = x_n\n",
    "Trainer.t = t_n\n",
    "\n",
    "def compute_loss(model, a, u, key, num_query_points=100):\n",
    "    \"\"\"Computes the loss of the model.\n",
    "    Returns the l2 loss, averaged over the batch. The loss is computed by randomly selecting query points from the input data and evaluating the model at those points.\n",
    "\n",
    "    Args:\n",
    "        model (eqx.Module): The model to evaluate.\n",
    "        a (batch, number_of_sensors): The input data.\n",
    "        u (batch, num_query_points): The ground truth data at the query points.\n",
    "\n",
    "    Returns:\n",
    "        loss (scalar): The loss of the model for the given batch.\n",
    "    \"\"\"\n",
    "    batch_size, Np1, Mp1 = u.shape\n",
    "            \n",
    "    # Select random query indices\n",
    "    t_key, x_key = random.split(key, 2)\n",
    "    t_idx = random.randint(t_key, (batch_size, num_query_points), 0, Np1)\n",
    "    x_idx = random.randint(x_key, (batch_size, num_query_points), 0, Mp1)\n",
    "\n",
    "    # Select the ground truth data at the query points\n",
    "    # Has shape (batch_size, num_query_points)\n",
    "    u_at_query_points = u[jnp.arange(batch_size)[:, None], t_idx, x_idx]\n",
    "    \n",
    "    # For each input function, compute the prediction of the model at the query points. (inner vmap)\n",
    "    # Do this for each sample in the batch. (outer vmap)\n",
    "    # Has shape (batch_size, num_query_points)\n",
    "    u_pred = vmap(vmap(model, (None, 0, 0)))(a, Trainer.x[x_idx], Trainer.t[t_idx])\n",
    "    \n",
    "    #mse loss\n",
    "    if model.self_adaptive:\n",
    "        print(\"self adaptive\")\n",
    "        loss = jnp.mean(model.self_adaptive(t_idx, x_idx) * jnp.square((u_pred - u_at_query_points))) #MSE\n",
    "    else:\n",
    "        loss = jnp.mean(jnp.square(u_pred - u_at_query_points))\n",
    "\n",
    "    return loss\n",
    "\n",
    "Trainer.compute_loss = staticmethod(compute_loss)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all\")\n",
    "def make_step(model, opt_state, a, u, key):\n",
    "    \"\"\"Performs a single optimization step.\"\"\"\n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    \n",
    "    loss, grads = eqx.filter_value_and_grad(Trainer.compute_loss)(model, a, u, key)\n",
    "    updates, opt_state = Trainer.opt.update([grads], opt_state, value=loss)\n",
    "    model = eqx.apply_updates(model, updates[0])\n",
    "    \n",
    "    if model.self_adaptive:\n",
    "        # normalize λ\n",
    "        model = eqx.tree_at(lambda m : m.self_adaptive.λ, model, model.self_adaptive.λ/jnp.mean(model.self_adaptive.λ))        \n",
    "    \n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    \n",
    "    return model, opt_state, loss\n",
    "\n",
    "Trainer.make_step = staticmethod(make_step)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all-except-first\")\n",
    "def evaluate(model, a, u, key):\n",
    "    model = eqx.filter_shard(model, Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    return compute_loss(model, a, u, key)\n",
    "\n",
    "Trainer.evaluate = staticmethod(evaluate)\n",
    "\n",
    "# Create mesh for sharding (autoparallelism)\n",
    "num_devices = len(jax.devices())\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "devices = mesh_utils.create_device_mesh((num_devices, 1))\n",
    "sharding_u = jshard.PositionalSharding(devices).reshape(num_devices, 1, 1)\n",
    "sharding_a = jshard.PositionalSharding(devices)\n",
    "sharding = {\"a\": sharding_a, \"u\": sharding_u}\n",
    "replicated = sharding_a.replicate()\n",
    "\n",
    "# Set sharding and replicated as class attributes, since they are constant throughout the training\n",
    "Trainer.sharding_a = sharding_a\n",
    "Trainer.sharding_u = sharding_u\n",
    "Trainer.replicated = replicated\n",
    "\n",
    "# Define hyperparameters\n",
    "hparams = modified_deeponet.Hparams(number_of_sensors=NUMBER_OF_SENSORS,\n",
    "                                    period=(x_n[-1]-x_n[0]).item(),\n",
    "                                    width=100,\n",
    "                                    depth=7,\n",
    "                                    learning_rate=1e-3,\n",
    "                                    interact_size=15,\n",
    "                                    λ_learning_rate=1e-3,\n",
    "                                    λ_mask=\"soft_relu\",\n",
    "                                    λ_shape=(N+1, M+1))\n",
    "\n",
    "# Define model\n",
    "model = ModifiedDeepONet(hparams)\n",
    "model = eqx.filter_shard(model, replicated)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = jdl.DataLoader(jdl.ArrayDataset(a_train_n, u_train_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "val_loader = jdl.DataLoader(jdl.ArrayDataset(a_val_n, u_val_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "\n",
    "# OPTIMIZER \n",
    "PATIENCE = 5 # Number of epochs with no improvement after which learning rate will be reduced\n",
    "COOLDOWN = 0 # Number of epochs to wait before resuming normal operation after the learning rate reduction\n",
    "FACTOR = 0.5  # Factor by which to reduce the learning rate:\n",
    "RTOL = 1e-4  # Relative tolerance for measuring the new optimum:\n",
    "ACCUMULATION_SIZE = 200 # Number of iterations to accumulate an average value:\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "θ_learning_rate = 1e-3\n",
    "λ_learning_rate = 1e-2\n",
    "\n",
    "θ_optimizer = optax.chain(\n",
    "    optax.adam(θ_learning_rate),\n",
    "    reduce_on_plateau(\n",
    "        patience=PATIENCE,\n",
    "        cooldown=COOLDOWN,\n",
    "        factor=FACTOR,\n",
    "        rtol=RTOL,\n",
    "        accumulation_size=ACCUMULATION_SIZE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "λ_optimizer = optax.chain(optax.adam(λ_learning_rate), optax.scale(-1.))\n",
    "\n",
    "opt = optax.multi_transform({'θ': θ_optimizer, 'λ': λ_optimizer}, param_labels=param_labels)\n",
    "opt_state = opt.init(eqx.filter([model], eqx.is_array))\n",
    "\n",
    "\n",
    "trainer = Trainer(model, opt, opt_state, train_loader, val_loader, hparams = hparams, animate=True, max_epochs=30, save_path=PATH)\n",
    "trainer(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc5dcd86a084ce3897a46e2604f1b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-23 20:59:34,290] Trial 3 failed with parameters: {'width': 112, 'depth': 7, 'interact_size': 7, 'θ_learning_rate': 0.00518442340053089, 'λ_learning_rate': 0.0019259546699044615} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\networks\\modified_deeponet.py\", line 132, in __call__\n",
      "    trainer()\n",
      "  File \"c:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\utils\\trainer.py\", line 170, in __call__\n",
      "    self._train_epoch(epoch_idx, train_key)\n",
      "  File \"c:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\utils\\trainer.py\", line 204, in _train_epoch\n",
      "    model, opt_state, train_loss_batch = Trainer.make_step(model, opt_state, batch_a, batch_u, keys[i])\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\equinox\\_jit.py\", line 239, in __call__\n",
      "    return self._call(False, args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\equinox\\_module.py\", line 1093, in __call__\n",
      "    return self.__func__(self.__self__, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\equinox\\_jit.py\", line 210, in _call\n",
      "    out = self._cached(dynamic_donate, dynamic_nodonate, static)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-23 20:59:34,293] Trial 3 failed with value None.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 164\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar(mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    163\u001b[0m     p\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mupdate(p\u001b[38;5;241m.\u001b[39mtrials_id, total \u001b[38;5;241m=\u001b[39m num_trials)\n\u001b[1;32m--> 164\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_deeponet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHparamTuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mNUMBER_OF_SENSORS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx_n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\networks\\modified_deeponet.py:132\u001b[0m, in \u001b[0;36mHparamTuning.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    129\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39minit(eqx\u001b[38;5;241m.\u001b[39mfilter([model], eqx\u001b[38;5;241m.\u001b[39mis_array))\n\u001b[0;32m    131\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, opt, opt_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader, trial\u001b[38;5;241m=\u001b[39mtrial, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m--> 132\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m last_val_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcurrent_val_loss\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_val_loss\n",
      "File \u001b[1;32mc:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\utils\\trainer.py:170\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[1;34m(self, max_epochs, key)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mepochs_id)\n\u001b[0;32m    168\u001b[0m key, train_key, val_key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_every_n_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_epoch(epoch_idx, val_key)\n",
      "File \u001b[1;32mc:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\test_problems\\..\\utils\\trainer.py:204\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self, epoch_idx, key)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mtrain_id) \n\u001b[0;32m    203\u001b[0m batch_a, batch_u \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mfilter_shard((batch_a, batch_u), (Trainer\u001b[38;5;241m.\u001b[39msharding_a, Trainer\u001b[38;5;241m.\u001b[39msharding_u))\n\u001b[1;32m--> 204\u001b[0m model, opt_state, train_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m train_loss_batch_item \u001b[38;5;241m=\u001b[39m train_loss_batch\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_history_batch[epoch_idx\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_batches \u001b[38;5;241m+\u001b[39m i] \u001b[38;5;241m=\u001b[39m train_loss_batch_item\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\eirik\\anaconda3\\envs\\prosjektoppgave\\Lib\\site-packages\\equinox\\_jit.py:210\u001b[0m, in \u001b[0;36m_JitWrapper._call\u001b[1;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    207\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome donated buffers were not usable*\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         )\n\u001b[1;32m--> 210\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_donate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_nodonate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached(dynamic_donate, dynamic_nodonate, static)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax \n",
    "from optax.contrib import reduce_on_plateau\n",
    "from jax import vmap\n",
    "import jax_dataloader as jdl\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "import jax.experimental.mesh_utils as mesh_utils\n",
    "import jax.sharding as jshard\n",
    "\n",
    "#PATH = \"/cluster/work/eirikaf/\"\n",
    "PATH = r\"C:\\Users\\eirik\\orbax\"\n",
    "#PATH = None\n",
    "\n",
    "# LOAD DATA\n",
    "#data = jnp.load(\"/cluster/home/eirikaf/phlearn-summer24/eirik_prosjektoppgave/data/advection.npz\")\n",
    "data = jnp.load(r\"C:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\data\\advection.npz\")\n",
    "x = jnp.array(data['x'])\n",
    "t = jnp.array(data['t'])\n",
    "a_train = jnp.array(data['a_train'])\n",
    "u_train = jnp.array(data['u_train'])\n",
    "a_val = jnp.array(data['a_val'])\n",
    "u_val = jnp.array(data['u_val'])\n",
    "a_test = jnp.array(data['a_test'])\n",
    "u_test = jnp.array(data['u_test'])\n",
    "\n",
    "# SET PARAMETERS\n",
    "P = x[-1]\n",
    "T = t[-1]\n",
    "M = len(x) - 1\n",
    "N = len(t) - 1\n",
    "NUMBER_OF_SENSORS = M + 1\n",
    "N = len(t)-1\n",
    "\n",
    "# NORMALIZE DATA\n",
    "u_normalizer = UnitGaussianNormalizer(u_train)\n",
    "a_normalizer = UnitGaussianNormalizer(a_train)\n",
    "x_normalizer = UnitGaussianNormalizer(x)\n",
    "t_normalizer = UnitGaussianNormalizer(t)\n",
    "\n",
    "u_train_n = u_normalizer.encode(u_train)\n",
    "a_train_n = a_normalizer.encode(a_train)\n",
    "\n",
    "u_val_n = u_normalizer.encode(u_val)\n",
    "a_val_n = a_normalizer.encode(a_val)\n",
    "\n",
    "x_n = x_normalizer.encode(x)\n",
    "t_n = t_normalizer.encode(t)\n",
    "\n",
    "# Set x and t as class attributes, since they are constant throughout the training\n",
    "Trainer.x = x_n\n",
    "Trainer.t = t_n\n",
    "\n",
    "def compute_loss(model, a, u, key, num_query_points=100):\n",
    "    \"\"\"Computes the loss of the model.\n",
    "    Returns the l2 loss, averaged over the batch. The loss is computed by randomly selecting query points from the input data and evaluating the model at those points.\n",
    "\n",
    "    Args:\n",
    "        model (eqx.Module): The model to evaluate.\n",
    "        a (batch, number_of_sensors): The input data.\n",
    "        u (batch, num_query_points): The ground truth data at the query points.\n",
    "\n",
    "    Returns:\n",
    "        loss (scalar): The loss of the model for the given batch.\n",
    "    \"\"\"\n",
    "    batch_size, Np1, Mp1 = u.shape\n",
    "            \n",
    "    # Select random query indices\n",
    "    t_key, x_key = random.split(key, 2)\n",
    "    t_idx = random.randint(t_key, (batch_size, num_query_points), 0, Np1)\n",
    "    x_idx = random.randint(x_key, (batch_size, num_query_points), 0, Mp1)\n",
    "\n",
    "    # Select the ground truth data at the query points\n",
    "    # Has shape (batch_size, num_query_points)\n",
    "    u_at_query_points = u[jnp.arange(batch_size)[:, None], t_idx, x_idx]\n",
    "    \n",
    "    # For each input function, compute the prediction of the model at the query points. (inner vmap)\n",
    "    # Do this for each sample in the batch. (outer vmap)\n",
    "    # Has shape (batch_size, num_query_points)\n",
    "    u_pred = vmap(vmap(model, (None, 0, 0)))(a, Trainer.x[x_idx], Trainer.t[t_idx])\n",
    "    \n",
    "    #mse loss\n",
    "    if model.self_adaptive:\n",
    "        loss = jnp.mean(model.self_adaptive(t_idx, x_idx) * jnp.square((u_pred - u_at_query_points))) #MSE\n",
    "    else:\n",
    "        loss = jnp.mean(jnp.square(u_pred - u_at_query_points))\n",
    "\n",
    "    return loss\n",
    "\n",
    "Trainer.compute_loss = staticmethod(compute_loss)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all\")\n",
    "def make_step(model, opt_state, a, u, key):\n",
    "    \"\"\"Performs a single optimization step.\"\"\"\n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    \n",
    "    loss, grads = eqx.filter_value_and_grad(Trainer.compute_loss)(model, a, u, key)\n",
    "    updates, opt_state = Trainer.opt.update([grads], opt_state, value=loss)\n",
    "    model = eqx.apply_updates(model, updates[0])\n",
    "    \n",
    "    if model.self_adaptive:\n",
    "        # normalize λ\n",
    "        model = eqx.tree_at(lambda m : m.self_adaptive.λ, model, model.self_adaptive.λ/jnp.mean(model.self_adaptive.λ))        \n",
    "    \n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    \n",
    "    return model, opt_state, loss\n",
    "\n",
    "Trainer.make_step = staticmethod(make_step)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all-except-first\")\n",
    "def evaluate(model, a, u, key):\n",
    "    model = eqx.filter_shard(model, Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    return compute_loss(model, a, u, key)\n",
    "\n",
    "Trainer.evaluate = staticmethod(evaluate)\n",
    "\n",
    "# Create mesh for sharding (autoparallelism)\n",
    "num_devices = len(jax.devices())\n",
    "devices = mesh_utils.create_device_mesh((num_devices, 1))\n",
    "sharding_u = jshard.PositionalSharding(devices).reshape(num_devices, 1, 1)\n",
    "sharding_a = jshard.PositionalSharding(devices)\n",
    "sharding = {\"a\": sharding_a, \"u\": sharding_u}\n",
    "replicated = sharding_a.replicate()\n",
    "\n",
    "# Set sharding and replicated as class attributes, since they are constant throughout the training\n",
    "Trainer.sharding_a = sharding_a\n",
    "Trainer.sharding_u = sharding_u\n",
    "Trainer.replicated = replicated\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = jdl.DataLoader(jdl.ArrayDataset(a_train_n, u_train_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "val_loader = jdl.DataLoader(jdl.ArrayDataset(a_val_n, u_val_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "\n",
    "num_trials = 10\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name='test12345',\n",
    "    storage=f\"sqlite:///optuna/optuna.db\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=50),\n",
    "    sampler = optuna.samplers.TPESampler(seed=2),\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "with ProgressBar(mode = \"trial\") as p:\n",
    "    p.pbar.update(p.trials_id, total = num_trials)\n",
    "    study.optimize(modified_deeponet.HparamTuning(train_loader, \n",
    "                                                  val_loader, \n",
    "                                                  NUMBER_OF_SENSORS, \n",
    "                                                  (x_n[-1]-x_n[0]).item(),\n",
    "                                                  (N+1, M+1),\n",
    "                                                  max_epochs=30), \n",
    "                    n_trials=num_trials, callbacks = [lambda study, trial: p.pbar.advance(p.trials_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m     15\u001b[0m jax\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax_enable_x64\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmesh_utils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmesh_utils\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networks'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"\")\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax \n",
    "from jax import vmap\n",
    "import jax_dataloader as jdl\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "import jax.experimental.mesh_utils as mesh_utils\n",
    "import jax.sharding as jshard\n",
    "\n",
    "#PATH = \"/cluster/work/eirikaf/\"\n",
    "PATH = r\"C:\\Users\\eirik\\orbax\"\n",
    "#PATH = None\n",
    "\n",
    "# LOAD DATA\n",
    "#data = jnp.load(\"/cluster/home/eirikaf/phlearn-summer24/eirik_prosjektoppgave/data/advection.npz\")\n",
    "data = jnp.load(r\"C:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\data\\advection.npz\")\n",
    "x = jnp.array(data['x'])\n",
    "t = jnp.array(data['t'])\n",
    "a_train = jnp.array(data['a_train'])\n",
    "u_train = jnp.array(data['u_train'])\n",
    "a_val = jnp.array(data['a_val'])\n",
    "u_val = jnp.array(data['u_val'])\n",
    "a_test = jnp.array(data['a_test'])\n",
    "u_test = jnp.array(data['u_test'])\n",
    "\n",
    "# SET PARAMETERS\n",
    "P = x[-1]\n",
    "T = t[-1]\n",
    "M = len(x) - 1\n",
    "N = len(t) - 1\n",
    "NUMBER_OF_SENSORS = M + 1\n",
    "N = len(t)-1\n",
    "\n",
    "# Pre-repeat data \n",
    "a_train = jnp.repeat(a_train[:, None, :], N+1, axis=1)\n",
    "a_val = jnp.repeat(a_val[:, None, :], N+1, axis=1)\n",
    "a_test = jnp.repeat(a_test[:, None, :], N+1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.repeat(x[None, :], N+1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = jnp.repeat(t[:, None], M+1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89c13cee699464fa6dfe1e1dcfe4201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(26, 26)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "(26, 26)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(26, 26)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "(26, 26)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(26, 26)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "(26, 26)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax \n",
    "from optax.contrib import reduce_on_plateau\n",
    "from jax import vmap\n",
    "import jax_dataloader as jdl\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "import jax.experimental.mesh_utils as mesh_utils\n",
    "import jax.sharding as jshard\n",
    "\n",
    "#PATH = \"/cluster/work/eirikaf/\"\n",
    "PATH = r\"C:\\Users\\eirik\\orbax\"\n",
    "#PATH = None\n",
    "\n",
    "# LOAD DATA\n",
    "#data = jnp.load(\"/cluster/home/eirikaf/phlearn-summer24/eirik_prosjektoppgave/data/advection.npz\")\n",
    "data = jnp.load(r\"C:\\Users\\eirik\\OneDrive - NTNU\\5. klasse\\prosjektoppgave\\eirik_prosjektoppgave\\data\\advection.npz\")\n",
    "x = jnp.array(data['x'])\n",
    "t = jnp.array(data['t'])\n",
    "a_train = jnp.array(data['a_train'])\n",
    "u_train = jnp.array(data['u_train'])\n",
    "a_val = jnp.array(data['a_val'])\n",
    "u_val = jnp.array(data['u_val'])\n",
    "a_test = jnp.array(data['a_test'])\n",
    "u_test = jnp.array(data['u_test'])\n",
    "\n",
    "# SET PARAMETERS\n",
    "P = x[-1]\n",
    "T = t[-1]\n",
    "M = len(x) - 1\n",
    "N = len(t) - 1\n",
    "NUMBER_OF_SENSORS = M + 1\n",
    "N = len(t)-1\n",
    "\n",
    "# NORMALIZE DATA\n",
    "u_normalizer = UnitGaussianNormalizer(u_train)\n",
    "a_normalizer = UnitGaussianNormalizer(a_train)\n",
    "x_normalizer = UnitGaussianNormalizer(x)\n",
    "t_normalizer = UnitGaussianNormalizer(t)\n",
    "\n",
    "u_train_n = u_normalizer.encode(u_train)\n",
    "a_train_n = a_normalizer.encode(a_train)\n",
    "\n",
    "u_val_n = u_normalizer.encode(u_val)\n",
    "a_val_n = a_normalizer.encode(a_val)\n",
    "\n",
    "u_test_n = u_normalizer.encode(u_test)\n",
    "a_test_n = a_normalizer.encode(a_test)\n",
    "\n",
    "x_n = x_normalizer.encode(x)\n",
    "t_n = t_normalizer.encode(t)\n",
    "\n",
    "# Pre-repeat data \n",
    "a_train_n = jnp.repeat(a_train_n[:, None, :], N+1, axis=1)\n",
    "a_val_n = jnp.repeat(a_val_n[:, None, :], N+1, axis=1)\n",
    "a_test_n = jnp.repeat(a_test_n[:, None, :], N+1, axis=1)\n",
    "\n",
    "x_n = jnp.repeat(x_n[None, :], N+1, axis=0)\n",
    "t_n = jnp.repeat(t_n[:, None], M+1, axis=1)\n",
    "\n",
    "# Set x and t as class attributes, since they are constant throughout the training\n",
    "Trainer.x = x_n\n",
    "Trainer.t = t_n\n",
    "\n",
    "def compute_loss(model, a, u, key, num_query_points=100):\n",
    "    \"\"\"Computes the loss of the model.\n",
    "    Returns the l2 loss, averaged over the batch. The loss is computed by randomly selecting query points from the input data and evaluating the model at those points.\n",
    "\n",
    "    Args:\n",
    "        model (eqx.Module): The model to evaluate.\n",
    "        a (batch, number_of_sensors): The input data.\n",
    "        u (batch, num_query_points): The ground truth data at the query points.\n",
    "\n",
    "    Returns:\n",
    "        loss (scalar): The loss of the model for the given batch.\n",
    "    \"\"\"\n",
    "    batch_size, Np1, Mp1 = u.shape\n",
    "    \n",
    "    a, x, t = a[:,::4,::4], Trainer.x[::4,::4], Trainer.t[::4,::4]\n",
    "    u = u[:,::4,::4]\n",
    "\n",
    "    u_pred = vmap(model, (0, None, None))(a, x, t)\n",
    "    \n",
    "    #mse loss\n",
    "    if model.self_adaptive:\n",
    "        loss = jnp.mean(model.self_adaptive() * jnp.square((u_pred - u))) #MSE\n",
    "    else:\n",
    "        loss = jnp.mean(jnp.square(u_pred - u))\n",
    "\n",
    "    return loss\n",
    "\n",
    "Trainer.compute_loss = staticmethod(compute_loss)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all\")\n",
    "def make_step(model, opt_state, a, u, key):\n",
    "    \"\"\"Performs a single optimization step.\"\"\"\n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    \n",
    "    loss, grads = eqx.filter_value_and_grad(Trainer.compute_loss)(model, a, u, key)\n",
    "    updates, opt_state = Trainer.opt.update([grads], opt_state, value=loss)\n",
    "    model = eqx.apply_updates(model, updates[0])\n",
    "    \n",
    "    if model.self_adaptive:\n",
    "        # normalize λ\n",
    "        model = eqx.tree_at(lambda m : m.self_adaptive.λ, model, model.self_adaptive.λ/jnp.mean(model.self_adaptive.λ))        \n",
    "    \n",
    "    model, opt_state = eqx.filter_shard((model, opt_state), Trainer.replicated)\n",
    "    \n",
    "    return model, opt_state, loss\n",
    "\n",
    "Trainer.make_step = staticmethod(make_step)\n",
    "\n",
    "@eqx.filter_jit(donate=\"all-except-first\")\n",
    "def evaluate(model, a, u, key):\n",
    "    model = eqx.filter_shard(model, Trainer.replicated)\n",
    "    a, u = eqx.filter_shard((a,u), (Trainer.sharding_a, Trainer.sharding_u))\n",
    "    return compute_loss(model, a, u, key)\n",
    "\n",
    "Trainer.evaluate = staticmethod(evaluate)\n",
    "\n",
    "# Create mesh for sharding (autoparallelism)\n",
    "num_devices = len(jax.devices())\n",
    "devices = mesh_utils.create_device_mesh((num_devices, 1, 1))\n",
    "sharding = jshard.PositionalSharding(devices)\n",
    "replicated = sharding.replicate()\n",
    "\n",
    "# Set sharding and replicated as class attributes, since they are constant throughout the training\n",
    "Trainer.sharding_a = sharding\n",
    "Trainer.sharding_u = sharding\n",
    "Trainer.replicated = replicated\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = jdl.DataLoader(jdl.ArrayDataset(a_train_n, u_train_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "val_loader = jdl.DataLoader(jdl.ArrayDataset(a_val_n, u_val_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "\n",
    "# Define hyperparameters\n",
    "hparams = fno2d.Hparams(n_blocks=4,\n",
    "                        hidden_dim=100,\n",
    "                        modes_max=10,)\n",
    "\n",
    "# Define model\n",
    "model = FNO2d(hparams)\n",
    "model = eqx.filter_shard(model, replicated)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = jdl.DataLoader(jdl.ArrayDataset(a_train_n, u_train_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "val_loader = jdl.DataLoader(jdl.ArrayDataset(a_val_n, u_val_n), batch_size=16, shuffle=True, backend='jax', drop_last=True)\n",
    "\n",
    "# OPTIMIZER \n",
    "PATIENCE = 5 # Number of epochs with no improvement after which learning rate will be reduced\n",
    "COOLDOWN = 0 # Number of epochs to wait before resuming normal operation after the learning rate reduction\n",
    "FACTOR = 0.5  # Factor by which to reduce the learning rate:\n",
    "RTOL = 1e-4  # Relative tolerance for measuring the new optimum:\n",
    "ACCUMULATION_SIZE = 200 # Number of iterations to accumulate an average value:\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "θ_learning_rate = 1e-3\n",
    "\n",
    "opt = optax.chain(\n",
    "    optax.adam(θ_learning_rate),\n",
    "    reduce_on_plateau(\n",
    "        patience=PATIENCE,\n",
    "        cooldown=COOLDOWN,\n",
    "        factor=FACTOR,\n",
    "        rtol=RTOL,\n",
    "        accumulation_size=ACCUMULATION_SIZE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "opt_state = opt.init(eqx.filter([model], eqx.is_array))\n",
    "\n",
    "trainer = Trainer(model, \n",
    "                  opt, \n",
    "                  opt_state, \n",
    "                  train_loader, \n",
    "                  val_loader, \n",
    "                  hparams = hparams, \n",
    "                  animate=True,\n",
    "                  save_path=PATH)\n",
    "trainer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import optimistix as optx\n",
    "from functools import partial\n",
    "import equinox as eqx\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "key = random.key(0)\n",
    "\n",
    "#################PARAMETERS####################\n",
    "\n",
    "η = 6.0\n",
    "γ = 1.0\n",
    "P = 20 # period (and end of the domain)\n",
    "M = 100 # M+1 equally spaced points in the domain, but we exclude the last one due to periodicity\n",
    "N = 200 # N+1 time points \n",
    "\n",
    "t0 = 0.0 # initial time\n",
    "t_final = 2.0 # end time\n",
    "\n",
    "dt = t_final / N # time step\n",
    "dx = P / M # space step\n",
    "\n",
    "x0 = 0.0 # initial position\n",
    "x_final = P-dx # final position (excluding the last point due to periodicity)\n",
    "\n",
    "x = jnp.linspace(x0, x_final, M) # domain\n",
    "t = jnp.linspace(t0, t_final, N+1) # time domain\n",
    "\n",
    "args = {\"η\" : η, \"γ\": γ, \"dx\" : dx}\n",
    "\n",
    "###############INITIAL CONDITION####################\n",
    "\n",
    "def sech(x): return 1/jnp.cosh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_condition_kdv(x, key, P=20):\n",
    "    \"\"\"\n",
    "    Generate the initial condition for the Korteweg-de Vries (KdV) equation.\n",
    "    Parameters:\n",
    "        x (float or array-like) : A single point or array in the spatial domain. \n",
    "        key (jax.random.PRNGKey): The random key for generating random numbers.\n",
    "        η (float, optional): The coefficient for the KdV equation. Default is 6.\n",
    "        P (float, optional): The period of the spatial domain. Default is 20.\n",
    "    Returns:\n",
    "        array-like: The initial condition for the KdV equation.\n",
    "    \"\"\"\n",
    "    \n",
    "    key_cs, key_ds = random.split(key, 2)\n",
    "    c1, c2 = random.uniform(key_cs, minval=0.5, maxval=2, shape=(2,))\n",
    "    d1, d2 = random.uniform(key_ds, minval=0, maxval=1, shape=(2,))\n",
    "    \n",
    "    a = c1**2 * sech(c1 * ((x+P/2-P*d1) % P - P/2))**2\n",
    "    a += c2**2 * sech(c2 * ((x+P/2-P*d2) % P - P/2))**2\n",
    "    return 2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_analytical(x, t, key, P=20):    \n",
    "    key_cs, key_ds = random.split(key, 2)\n",
    "    c = random.uniform(key_cs, minval=0.5, maxval=2, shape=())\n",
    "    d = random.uniform(key_ds, minval=0, maxval=1, shape=())\n",
    "    \n",
    "    return 2 * c**2 * sech(c * ((x-c*t+P/2-P*d) % P - P/2))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e5ffdf9dc0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, u_analytical(x, 4, random.key(0), P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosjektoppgave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
